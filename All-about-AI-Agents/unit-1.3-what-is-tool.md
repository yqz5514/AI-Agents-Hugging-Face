# üìå AI Agent Tools

## 1. Introduction: What Are AI Tools?
AI agents use **tools** to take actions beyond their internal knowledge. A **Tool** is a function provided to the LLM to fulfill a **clear objective**.

### üîπ Commonly Used AI Tools
| **Tool**           | **Description** |
|-------------------|---------------|
| **Web Search**    | Fetches up-to-date information from the internet. |
| **Image Generation** | Creates images based on text descriptions. |
| **Retrieval**     | Retrieves information from an external source. |
| **API Interface** | Interacts with an external API (GitHub, YouTube, Spotify, etc.). |

üìå **A good tool should complement the power of an LLM rather than replace it.**  
üìå **If an agent needs up-to-date data, it must obtain it via a tool.**

### üîπ A Tool Should Contain:
1. **A textual description** of what the function does.
2. **A callable function** (performs an action).
3. **Arguments** with proper typing.
4. *(Optional)* **Outputs** with proper typing.

---

## 2. How Do Tools Work?
LLMs **only process text**‚Äîthey cannot call tools themselves. Instead, they **generate text-based commands** that an **Agent** interprets and executes.

### üîπ How an LLM Uses a Tool:
1. The LLM detects when a tool is required.
2. It generates **text instructions** to invoke the tool.
3. The **Agent parses the LLM‚Äôs output** and recognizes a tool call.
4. The Agent **executes the tool function** and retrieves the output.
5. The result is **passed back to the LLM**, which generates the final response.

üìå **The tool call is hidden from the user‚Äîthe Agent processes everything behind the scenes.**

### üîπ Example: Weather Tool Call
1Ô∏è‚É£ **User asks:** "What‚Äôs the weather in Paris?"  
2Ô∏è‚É£ **LLM generates text:** `CALL weather_tool("Paris")`  
3Ô∏è‚É£ **Agent executes the tool:** Fetches weather data via an API.  
4Ô∏è‚É£ **LLM responds:** "The weather in Paris is 18¬∞C and sunny."

---

## 3. How Do We Give Tools to an LLM?
Tools are **described in the system prompt**.  

### üîπ To define a tool, we must specify:
- **What the tool does**
- **What exact inputs it expects**  

Tools are typically provided using structured formats such as **JSON** or programming languages.

### üîπ Example: Defining a Simple Calculator Tool
We will implement a basic **multiplication tool** in Python:
```python
def calculator(a: int, b: int) -> int:
    """Multiply two integers."""
    return a * b
```

### ‚úÖ Tool Breakdown:

- Name: "calculator"
- Description: "Multiply two integers."
- Arguments:
a (int): First number
b (int): Second number
- Output: (int): The product of a and b

### üìå The textual description is what we provide to the LLM so it knows how to use the tool.

---

### 3.1 Auto-Formatting Tool Descriptions
Since tools are written in Python, we can automatically generate their descriptions by using function introspection.

#### üîπ Using a Python Decorator for Tools
Instead of manually describing each tool, we use a @tool decorator that extracts metadata:
```
@tool
def calculator(a: int, b: int) -> int:
    """Multiply two integers."""
    return a * b
```
#### üîπ Auto-Generated Tool Description:

```
Tool Name: calculator, Description: Multiply two integers., Arguments: a: int, b: int, Outputs: int
```
#### üìå Automating tool descriptions ensures LLMs receive structured and consistent specifications.
---

### 3.2 Generic Tool Implementation
To create a reusable tool system, we define a Tool class:

```
class Tool:
    """
    A class representing a reusable piece of code (Tool).

    Attributes:
        name (str): Name of the tool.
        description (str): A textual description of what the tool does.
        func (callable): The function this tool wraps.
        arguments (list): A list of arguments.
        outputs (str or list): The return type(s) of the wrapped function.
    """
    def __init__(self, name, description, func, arguments, outputs):
        self.name = name
        self.description = description
        self.func = func
        self.arguments = arguments
        self.outputs = outputs

    def to_string(self):
        """
        Return a string representation of the tool, including its metadata.
        """
        args_str = ", ".join([f"{arg_name}: {arg_type}" for arg_name, arg_type in self.arguments])
        return f"Tool Name: {self.name}, Description: {self.description}, Arguments: {args_str}, Outputs: {self.outputs}"

    def __call__(self, *args, **kwargs):
        return self.func(*args, **kwargs)
```

#### üîπ Creating a Tool Instance

```
calculator_tool = Tool(
    "calculator",
    "Multiply two integers.",
    calculator,
    [("a", "int"), ("b", "int")],
    "int",
)
```
#### üìå This makes tool management modular and reusable across different applications.
---
#### 3.2.1 Automating Tool Extraction Using Inspect
To further automate tool descriptions, we use Python‚Äôs inspect module:

```
import inspect

def tool(func):
    """
    A decorator that extracts function metadata and creates a Tool instance.
    """
    signature = inspect.signature(func)
    arguments = [(param.name, str(param.annotation)) for param in signature.parameters.values()]
    return_annotation = str(signature.return_annotation) if signature.return_annotation != inspect._empty else "No return annotation"
    
    return Tool(
        name=func.__name__,
        description=func.__doc__ or "No description provided.",
        func=func,
        arguments=arguments,
        outputs=return_annotation
    )
```

##### ‚úÖ Benefits:

- Extracts function metadata dynamically.
- Ensures consistent tool descriptions.
- Supports easy expansion of tool libraries.

##### üîπ Using the Decorator

```
@tool
def calculator(a: int, b: int) -> int:
    """Multiply two integers."""
    return a * b

print(calculator.to_string())
```
##### üìå Now the tool‚Äôs specification is automatically extracted without needing manual updates.
---

## üìå Key Takeaways (3-Sentence Summary)
### **1Ô∏è‚É£ AI Tools allow LLMs to perform external actions, such as fetching data or executing functions.**
### **2Ô∏è‚É£ Tools must be well-defined with a name, description, expected inputs, and outputs to ensure LLMs can invoke them correctly.**
### **3Ô∏è‚É£ Automating tool descriptions using decorators and introspection simplifies tool integration and maintains consistency.**
---
## üìå If an Interviewer Asks...
### ‚ùì Q1: Why do AI agents need tools?
#### ‚úÖ Answer: AI agents rely on tools to overcome knowledge limitations, fetch real-time data, and execute specialized functions beyond their training scope.

### ‚ùì Q2: How does an LLM call a tool?
#### ‚úÖ Answer: The LLM generates text commands indicating a tool call, which the Agent interprets and executes, then feeds the result back to the model.

### ‚ùì Q3: Why is automating tool descriptions important?
#### ‚úÖ Answer: Automating descriptions ensures consistency, reduces manual errors, and simplifies LLM integration by providing structured, machine-readable tool specifications.

### What is AI tool?
- An executable process or external API that allows agents to perform specific tasks and interact with external environments
- Functions that give LLMs extra capabilities, such as performing calculations or accessing external data.

### How do AI agents use tools as a form of ‚Äúacting‚Äù in an environment?
-  By asking the LLM to generate tool invocation code when appropriate and running tools on behalf of the model

### Which of the following best describes the role of special tokens in LLMs?
- They serve specific functions like marking the end of a sequence (EOS) or separating different message roles in chat models

### How do AI chat models process user messages internally?
- They convert user messages into a formatted prompt by concatenating system, user, and assistant messages

### How to Define a Tool: By providing a clear textual description, inputs, outputs, and a callable function.

### Why Tools Are Essential: They enable Agents to overcome the limitations of static model training, handle real-time tasks, and perform specialized actions.